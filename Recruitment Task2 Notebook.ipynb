{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading ham and spam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_filenames=os.listdir(os.path.join(\"spam\"))\n",
    "ham_filenames=os.listdir(os.path.join(\"easy_ham\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy\n",
    "def load_email(directory,filename):\n",
    "    with open(os.path.join(directory, filename), \"rb\") as f:\n",
    "     return email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(\"easy_ham\", filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(\"spam\", filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(ham_emails+spam_emails)\n",
    "Y=np.array([0]*len(ham_emails)+[1]*len(spam_emails))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all emails to plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def html_text(html):\n",
    "    soup = BeautifulSoup(html,\"html\")\n",
    "    return soup.get_text()\n",
    "    \n",
    "def email_to_text(email):\n",
    "    # Enter code  #\n",
    "    \n",
    "    return '''Return plain text'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anumeha/miniconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/anumeha/miniconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['will', 'just', 'more', 'about', 'list', 'which', 'would', 'only', 'like', 'people', 'some', 'email', 'other', 'been', 'mailing', 'make', 'also', 'free', 'because', 'into', 'could', 'time', 'over', 'were', 'should', 'here', 'first', 'most', 'even', 'want', 'please', 'using', 'where', 'many', 'know', 'after', 'does', 'much', 'same', 'need', 'message', 'very', 'send', 'money', 'good', 'work', 'such', 'being', 'before', 'find', 'take', 'linux', 'business', 'still', 'click', 'said', 'mail', 'information', 'really', 'line', 'every', 'world', 'since', 'best', 'made', 'software', 'something', 'internet', 'each', 'right', 'change', 'last', 'help', 'used', 'while', 'system', 'years', 'report', 'government', 'next', 'must', 'within', 'without', 'file', 'spam', 'well', 'messages', 'different', 'another', 'give', 'order', 'united', 'might', 'name', 'address', 'receive', 'sure', 'company', 'technology', 'back', 'found', 'going', 'never', 'anyone', 'look', 'once', 'home', 'sponsored', 'down', 'number', 'million', 'september', 'computer', 'better', 'states', 'security', 'keep', 'problem', 'data', 'probably', 'under', 'actually', 'come', 'against', 'between', 'long', 'great', 'someone', 'network', 'received', 'support', 'real', 'both', 'seems', 'call', 'less', 'files', 'program', 'code', 'unseen', 'user', 'sent', 'package', 'part', 'running', 'start', 'president', 'working', 'state', 'companies', 'read', 'american', 'life', 'wish', 'build', 'doing', 'supplied', 'looking', 'matthias', 'groups', 'check', 'least', 'subject', 'trying', 'access', 'little', 'service', 'anything', 'done', 'maybe', 'server', 'based', 'public', 'around', 'current', 'point', 'news', 'following', 'getting', 'version', 'perl', 'case', 'offer', 'total', 'easy', 'special', 'having', 'times', 'already', 'form', 'ever', 'bush', 'always', 'high', 'tell', 'nothing', 'year', 'says', 'rights', 'provide', 'able', 'remove', 'exmh', 'site', 'place', 'phone', 'called', 'political', 'problems', 'else', 'until', 'tried', 'large', 'upon', 'services', 'national', 'contact', 'msgs', 'open', 'making', 'seen', 'including', 'receiving', 'during', 'personal', 'link', 'enough', 'available', 'removed', 'test', 'install', 'save', 'irish', 'important', 'below', 'today', 'believe', 'future', 'seem', 'release', 'marketing', 'makes', 'legal', 'trade', 'country', 'error', 'several', 'rather', 'datapower', 'days', 'unsubscribe', 'become', 'given', 'financial', 'live', 'global', 'processing', 'market', 'capital', 'quite', 'instead', 'addresses', 'communications', 'spamassassin', 'product', 'process', 'source', 'simply', 'stop', 'august', 'currently', 'kind', 'online', 'further', 'person', 'idea', 'family', 'hard', 'cell', 'simple', 'whether', 'investment', 'packages', 'group', 'stuff', 'show', 'move', 'works', 'original', 'text', 'story', 'tired', 'months', 'second', 'small', 'allow', 'include', 'copy', 'came', 'application', 'either', 'means', 'full', 'kernel', 'pretty', 'digital', 'sending', 'welcome', 'chris', 'type', 'local', 'often', 'return', 'went', 'wrote', 'drive', 'international', 'load', 'week', 'power', 'word', 'posted', 'copyright', 'almost', 'complete', 'geek', 'whole', 'cash', 'understand', 'opportunity', 'credit', 'search', 'osdn', 'possible', 'everything', 'account', 'java', 'told', 'reply', 'again', 'office', 'development', 'training', 'lost', 'federal', 'remember', 'income', 'general', 'private', 'saou', 'create', 'price', 'women', 'systems', 'single', 'friends', 'feel', 'fact', 'visit', 'users', 'human', 'economic', 'control', 'recent', 'easily', 'october', 'looks', 'orders', 'venture', 'card', 'although', 'john', 'month', 'sell', 'major', 'learn', 'military', 'known', 'dollars', 'value', 'foreign', 'root', 'mean', 'page', 'growing', 'write', 'installed', 'away', 'content', 'deal', 'grants', 'directory', 'cannot', 'bill', 'needs', 'half', 'database', 'issue', 'gets', 'hours', 'university', 'razor', 'happy', 'invoked', 'interest', 'offers', 'past', 'domain', 'others', 'join', 'started', 'worth', 'force', 'worked', 'interested', 'cost', 'left', 'plan', 'reading', 'windows', 'kingdom', 'sponsor', 'reason', 'behalf', 'similar', 'plus', 'research', 'device', 'window', 'experience', 'sites', 'tied', 'latest', 'folder', 'claim', 'center', 'question', 'white', 'fall', 'according', 'policy', 'method', 'area', 'fill', 'false', 'numbers', 'early', 'bank', 'perhaps', 'performance', 'wanted', 'respect', 'reports', 'gives', 'rate', 'results', 'contains', 'alsa', 'finding', 'nice', 'lawrence', 'daily', 'response', 'rates', 'industry', 'course', 'standard', 'programs', 'exactly', 'increase', 'robert', 'continue', 'entire', 'wants', 'play', 'enenkio', 'generation', 'amount', 'true', 'comes', 'particular', 'management', 'corporation', 'fork', 'added', 'direct', 'building', 'various', 'insurance', 'black', 'article', 'late', 'interesting', 'above', 'needed', 'advertising', 'talking', 'emails', 'took', 'goes']\n"
     ]
    }
   ],
   "source": [
    "def clean_words(wordlist):\n",
    "    # Enter code to clean the data ,You can use anything that you want #\n",
    "   \n",
    "    return ''' List of words'''\n",
    "\n",
    "count=0\n",
    "word_list=[]\n",
    "for i in X_train:\n",
    "    mail=email_to_text(i)\n",
    "    if mail is not None:\n",
    "        words=None\n",
    "        words=mail.lower().split()\n",
    "        final_word=clean_words(words)\n",
    "        for w in final_word:\n",
    "            word_list.append(w)\n",
    "\n",
    "most_common_words= [word for word, word_count in Counter(word_list).most_common(500)]\n",
    "most_common = [item for item in Counter(word_list).most_common(500)]\n",
    "print(most_common_words)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anumeha/miniconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/anumeha/miniconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1500x500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38572 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform=[]\n",
    "for email in X_train[:1500]:    \n",
    "    mail=email_to_text(email)\n",
    "    X_word=[]\n",
    "    if mail is not None:\n",
    "        words=None\n",
    "        words=mail.lower().split()\n",
    "        for j in most_common_words:\n",
    "            num=words.count(j)\n",
    "            X_word.append(num)\n",
    "    \n",
    "    X_transform.append(X_word) \n",
    "\n",
    "from scipy import sparse\n",
    "sparse.csr_matrix(X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.95, total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.96, total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.968, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95933333333333337"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bonus Task #\n",
    "# Fine tune the hyperparameters #\n",
    "lg=RandomForestClassifier()\n",
    "lg.fit(X_transform,Y_train[:1500])\n",
    "score = cross_val_score(lg, X_transform, Y_train[:1500], cv=3, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
