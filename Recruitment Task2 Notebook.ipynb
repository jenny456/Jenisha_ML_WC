{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading ham and spam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_filenames=os.listdir(os.path.join(\"spam\"))\n",
    "ham_filenames=os.listdir(os.path.join(\"easy_ham\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy\n",
    "def load_email(directory,filename):\n",
    "    with open(os.path.join(directory, filename), \"rb\") as f:\n",
    "     return email.parser.BytesParser(policy=email.policy.default).parse(f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(\"easy_ham\", filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(\"spam\", filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(ham_emails+spam_emails)\n",
    "Y=np.array([0]*len(ham_emails)+[1]*len(spam_emails))\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all emails to plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def html_text(html):\n",
    "    soup = BeautifulSoup(html,\"html\")\n",
    "    return soup.get_text()\n",
    "    \n",
    "def email_to_text(email):\n",
    "    # Enter code  #\n",
    "    \n",
    "    return str(email.get_payload())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'get', 'list', 'would', 'new', 'use', 'people', 'like', 'email', 'mailing', 'make', 'also', 'free', 'could', 'time', 'even', 'first', 'think', 'many', 'want', 'may', 'using', 'know', 'see', 'way', 'much', 'please', 'send', 'need', 'message', 'good', 'work', 'money', 'take', 'find', 'linux', 'business', 'every', 'said', 'still', 'united', 'two', 'something', 'world', 'made', 'states', 'best', 'must', 'object', 'really', 'report', 'help', 'government', 'used', 'sep', 'change', 'right', 'line', 'since', 'mail', 'web', 'information', 'internet', 'years', 'name', 'another', 'got', 'software', 'next', 'old', 'address', 'last', 'found', 'within', 'without', 'might', 'file', 'spam', 'say', 'different', 'september', 'sure', 'never', 'going', 'run', 'messages', 'order', 'system', 'give', 'better', 'well', 'back', 'set', 'number', 'look', 'security', 'public', 'sponsored', 'keep', 'put', 'received', 'problem', 'great', 'data', 'actually', 'million', 'try', 'computer', 'home', 'start', 'less', 'come', 'anyone', 'someone', 'end', 'receive', 'probably', 'seems', 'day', 'american', 'per', 'long', 'build', 'read', 'things', 'times', 'support', 'click', 'files', 'around', 'lot', 'program', 'state', 'part', 'real', 'access', 'company', 'least', 'supplied', 'network', 'groups', 'aug', 'president', 'user', 'little', 'anything', 'xml', 'total', 'global', 'always', 'check', 'technology', 'running', 'looking', 'ever', 'matthias', 'working', 'thing', 'says', 'red', 'code', 'trying', 'done', 'call', 'trade', 'news', 'point', 'following', 'perl', 'package', 'subject', 'key', 'nothing', 'current', 'based', 'national', 'unseen', 'special', 'version', 'server', 'maybe', 'rights', 'case', 'bush', 'sent', 'open', 'provide', 'add', 'getting', 'international', 'life', 'easy', 'political', 'hat', 'already', 'making', 'able', 'wish', 'big', 'remove', 'irish', 'place', 'offer', 'year', 'service', 'rpm', 'receiving', 'become', 'contact', 'including', 'enough', 'let', 'called', 'html', 'tell', 'upon', 'else', 'link', 'three', 'tried', 'high', 'believe', 'save', 'development', 'msgs', 'future', 'problems', 'source', 'given', 'marketing', 'thought', 'large', 'personal', 'several', 'companies', 'hard', 'log', 'person', 'available', 'rather', 'war', 'pay', 'test', 'far', 'stuff', 'human', 'site', 'makes', 'important', 'move', 'economic', 'seem', 'stop', 'simple', 'phone', 'packages', 'power', 'install', 'seen', 'live', 'release', 'guide', 'second', 'buy', 'whether', 'via', 'thanks', 'women', 'return', 'text', 'small', 'training', 'today', 'kind', 'size', 'came', 'days', 'services', 'unsubscribe', 'java', 'allow', 'instead', 'went', 'original', 'cell', 'grants', 'often', 'financial', 'spamassassin', 'exmh', 'quite', 'tired', 'works', 'story', 'include', 'online', 'military', 'lost', 'simply', 'error', 'sending', 'group', 'show', 'kernel', 'idea', 'whole', 'communications', 'top', 'full', 'men', 'august', 'means', 'either', 'months', 'currently', 'told', 'copyright', 'country', 'legal', 'possible', 'pretty', 'word', 'form', 'welcome', 'feel', 'major', 'law', 'hit', 'almost', 'systems', 'thousands', 'due', 'everything', 'investment', 'geek', 'write', 'wrote', 'understand', 'type', 'federal', 'complete', 'bit', 'digital', 'removed', 'market', 'account', 'osdn', 'looks', 'recent', 'posted', 'past', 'yet', 'dollars', 'continue', 'cannot', 'application', 'half', 'false', 'private', 'fact', 'create', 'gets', 'orders', 'away', 'page', 'others', 'users', 'opportunity', 'office', 'process', 'single', 'friends', 'saou', 'directory', 'bill', 'sell', 'cash', 'response', 'product', 'database', 'bad', 'known', 'results', 'building', 'local', 'price', 'freedom', 'although', 'remember', 'control', 'value', 'foreign', 'general', 'drive', 'needs', 'tied', 'though', 'reason', 'windows', 'learn', 'month', 'family', 'cost', 'razor', 'income', 'alsa', 'reports', 'easily', 'potential', 'week', 'respect', 'box', 'countries', 'john', 'started', 'sponsor', 'force', 'similar', 'growing', 'capital', 'join', 'kingdom', 'act', 'worked', 'load', 'hours', 'increase', 'emails', 'protect', 'america', 'pgp', 'play', 'worth', 'across', 'research', 'mean', 'october', 'later', 'behalf', 'sex', 'exactly', 'daily', 'man', 'experience', 'rate', 'bank', 'needed', 'course', 'everyone', 'datapower', 'air', 'comes', 'method', 'color', 'advertising', 'question', 'ability', 'plan', 'early', 'center', 'programs', 'living', 'offers', 'wanted', 'article', 'lawrence', 'step', 'black', 'left', 'hope', 'enenkio', 'took', 'common', 'plus', 'search', 'installed', 'finding', 'sites', 'wants', 'mind', 'root', 'hardware', 'language', 'entire', 'copy', 'addresses', 'happy', 'direct', 'lots', 'university', 'various', 'according', 'gives', 'area', 'deal', 'white', 'love', 'thinking', 'amount', 'coming']\n"
     ]
    }
   ],
   "source": [
    "def clean_words(wordlist):\n",
    "    # Enter code to clean the data ,You can use anything that you want #\n",
    "    newlist=[]\n",
    "    stemmer=PorterStemmer()\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    for word in wordlist:\n",
    "        if (word.isalpha() and word not in stop_words and len(word)>2):\n",
    "            #can also implement stemming by stemmer.stem(word)\n",
    "            newlist.append(word)\n",
    "    return newlist\n",
    "\n",
    "count=0\n",
    "word_list=[]\n",
    "for i in X_train:\n",
    "    mail=email_to_text(i)\n",
    "    if mail is not None:\n",
    "        words=None\n",
    "        words=mail.lower().split()\n",
    "        final_word=clean_words(words)\n",
    "        for w in final_word:\n",
    "            word_list.append(w)\n",
    "\n",
    "most_common_words= [word for word, word_count in Counter(word_list).most_common(500)]\n",
    "most_common = [item for item in Counter(word_list).most_common(500)]\n",
    "print(most_common_words)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1500x500 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 34430 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform=[]\n",
    "for email in X_train[:1500]:    \n",
    "    mail=email_to_text(email)\n",
    "    X_word=[]\n",
    "    if mail is not None:\n",
    "        words=None\n",
    "        words=mail.lower().split()\n",
    "        for j in most_common_words:\n",
    "            num=words.count(j)\n",
    "            X_word.append(num)\n",
    "    \n",
    "    X_transform.append(X_word) \n",
    "\n",
    "from scipy import sparse\n",
    "sparse.csr_matrix(X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.912, total=   0.0s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... , score=0.928, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.95, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bonus Task #\n",
    "# Fine tune the hyperparameters #\n",
    "lg=RandomForestClassifier()\n",
    "lg.fit(X_transform,Y_train[:1500])\n",
    "score = cross_val_score(lg, X_transform, Y_train[:1500], cv=3, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
